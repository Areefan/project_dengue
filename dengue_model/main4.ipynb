{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlalchemy as sa\n",
    "from urllib.parse import quote\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "# import itertools\n",
    "# import statsmodels.api as sm\n",
    "# from pylab import rcParams\n",
    "\n",
    "import warnings; \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action=\"ignore\",category=UserWarning)\n",
    "warnings.simplefilter(action=\"ignore\",category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 10)\n",
    "plt.rcParams['grid.linestyle'] = ':'   \n",
    "plt.rcParams['axes.grid'] = True\n",
    "\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "#sns.color_palette(\"RdBu\", n_colors=10)\n",
    "\n",
    "np.float_ = np.float64\n",
    "\n",
    "# %matplotlib inline\n",
    "# %config InlineBackend.figure_formats = {'png', 'retina'}\n",
    "\n",
    "\n",
    "# from IPython.core.interactiveshell import InteractiveShell\n",
    "# InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "from prophet import Prophet\n",
    "from prophet.plot import add_changepoints_to_plot\n",
    "\n",
    "from statsmodels.tsa.statespace.varmax import VARMAX\n",
    "from statsmodels.tsa.vector_ar.var_model import VAR\n",
    "from statsmodels.tsa.vector_ar.vecm import coint_johansen\n",
    "\n",
    "\n",
    "print('Numpy version', np.__version__)\n",
    "print('Pandas version', pd.__version__)\n",
    "print('Seaborn version', sns.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_forecast_accuracy(y, y_hat):\n",
    "    # ME\n",
    "    me = (y - y_hat).sum()/len(y)\n",
    "\n",
    "    # RMSE\n",
    "    rmse = math.sqrt(mean_squared_error(y, y_hat))\n",
    "\n",
    "    # MAPE\n",
    "    mape = mean_absolute_percentage_error(y, y_hat) * 100\n",
    "    \n",
    "    # WAPE\n",
    "    wape = (y - y_hat).__abs__().sum() / y.__abs__().sum() * 100\n",
    "\n",
    "    print(\"ME: %.2f, RMSE: %.2f, MAPE: %.2f%%, WAPE: %.2f%%\" % (me,rmse,mape,wape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(\"current times:\", cur_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case = pd.read_csv(\"./r506_pipeline/data/df2.csv\", encoding=\"cp874\" )\n",
    "# temp = pd.read_csv(\"./temp_pipeline/data/dataset/temp.csv\", encoding=\"cp874\")\n",
    "# rain = pd.read_csv(\"./rain_pipeline/data/dataset/rain.csv\", encoding=\"cp874\")\n",
    "# press = pd.read_csv(\"./pressure_pipeline/data/dataset/press.csv\", encoding=\"cp874\")\n",
    "# humidity = pd.read_csv(\"./humidity_pipeline/data/dataset/humidity.csv\", encoding=\"cp874\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = case.merge(temp,on='date',how='left')\n",
    "# df = df.merge(press,on='date',how='left')\n",
    "# df = df.merge(humidity,on='date',how='left')\n",
    "# df = df.merge(rain,on='date',how='left')\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uscon = pd.read_csv('./data/weekly_summary.csv',header=0)\n",
    "uscon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uscon['date'] = pd.to_datetime(uscon['date'])\n",
    "uscon = uscon.set_index('date') \n",
    "weekly_summary = uscon.resample('W-MON').mean().interpolate(method='linear')\n",
    "# weekly_summary = uscon.resample('D').sum()\n",
    "# weekly_summary = weekly_summary[weekly_summary['total_case'] != 0]\n",
    "# weekly_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uscon = weekly_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAR(uscon)\n",
    "print(model.select_order())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def Augmented_Dickey_Fuller_Test_func(series , column_name):\n",
    "    print (f'Results of Dickey-Fuller Test for column: {column_name}')\n",
    "    dftest = adfuller(series, autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','No Lags Used','Number of Observations Used'])\n",
    "    print (dfoutput)\n",
    "    if dftest[1] <= 0.05:\n",
    "        print(\"Conclusion:====>\")\n",
    "        print(\"Reject the null hypothesis\")\n",
    "        print(\"Data is trend stationary\")\n",
    "    else:\n",
    "        print(\"Conclusion:====>\")\n",
    "        print(\"Fail to reject the null hypothesis\")\n",
    "        print(\"Data is stostochastic trend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, column in uscon.items():\n",
    "    Augmented_Dickey_Fuller_Test_func(uscon[name],name)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cointegration_test(df): \n",
    "    res = coint_johansen(df,0,3)\n",
    "    traces = res.lr1        # statistical test values\n",
    "    cvts = res.cvt[:,1]     # critical value at 95% CI\n",
    "    print('Column Name > Test Stat > C(95%) => Significant')\n",
    "    print('----------------------------------------------')\n",
    "    for col, trace, cvt in zip(df.columns, traces, cvts):\n",
    "        print(col, '>', round(trace,2), \">\", round(cvt,2), '=>' , trace > cvt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cointegration_test(uscon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio = 0.7\n",
    "train_size = int(len(uscon)*split_ratio)\n",
    "Y_train, Y_test = uscon[:train_size], uscon[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pq = (1,0)\n",
    "\n",
    "model = VARMAX(Y_train, order=best_pq, trend='c').fit(disp=False)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.forecast(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(uscon['total_case'], alpha=0.5, color='blue', label='Original')\n",
    "plt.plot(model.predict()['total_case'], marker='o', linestyle='--', alpha=0.5, color='green', label='Predicted')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "get_forecast_accuracy(Y_train['total_case'], model.predict()['total_case'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = [y for y in Y_train.values]\n",
    "train = history\n",
    "predictions = list()\n",
    "upper_ci = list()\n",
    "lower_ci = list()\n",
    "\n",
    "\n",
    "h = 4\n",
    "for t in range(len(Y_test)-(h-1)):\n",
    "      \n",
    "  model_fit = VARMAX(train, order=best_pq).fit(disp=False)\n",
    "    \n",
    "  output = model_fit.get_forecast(h)\n",
    "  predictions.append(output.predicted_mean[h-1])\n",
    "  lower_ci.append(output.conf_int()[h-1, 0])\n",
    "  upper_ci.append(output.conf_int()[h-1, 5])\n",
    "\n",
    "  history.append(Y_test.iloc[t])\n",
    "  train = history[t+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(Y_train['total_case'], label='Train set', color='red', alpha=0.6); \n",
    "plt.plot(Y_test['total_case'], label='Test set', color='blue', alpha=0.6); \n",
    "\n",
    "predictions_con = pd.Series([i[0] for i in predictions], index=Y_test.index[h-1:])\n",
    "plt.plot(predictions_con, 'go:', label='Predicted', alpha=0.6, ms=4) \n",
    "plt.fill_between(Y_test.index[h-1:], upper_ci, lower_ci, color='#ff0066', alpha=.25)\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout();\n",
    "\n",
    "get_forecast_accuracy(Y_test['total_case'][h-1:], predictions_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.forecast(h)\n",
    "results['total_case'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the total number of days to forecast (4 steps of 7 days each)\n",
    "n_forecast_days = 4 \n",
    "\n",
    "# Generate the forecast\n",
    "forecast = model.get_forecast(steps=n_forecast_days)\n",
    "\n",
    "# Create a date range starting from the day after the last date of the training data for 28 days\n",
    "last_date = Y_test.index[-1]\n",
    "\n",
    "# Generate the start date for each step\n",
    "forecast_dates = [last_date + timedelta(weeks=1 * i) for i in range(n_forecast_days)]\n",
    "# forecast_dates = pd.date_range(start=last_date + timedelta(days=1), periods=n_forecast_days)\n",
    "\n",
    "# Convert the forecasted mean to a DataFrame and assign the date range as the index\n",
    "forecast_mean = forecast.predicted_mean\n",
    "forecast_mean.index = forecast_dates\n",
    "\n",
    "# Print the forecast with dates\n",
    "print(forecast_mean)\n",
    "forecast_mean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'total_case' column to a Series\n",
    "total_case_series = forecast_mean['total_case']\n",
    "total_case_series = forecast_mean.loc[:, 'total_case']\n",
    "# total_case_series = forecast_mean.loc[:, 'total_case', 'temp']\n",
    "total_case_series = forecast_mean['total_case']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Series to DataFrame\n",
    "total_case_series = total_case_series.reset_index()\n",
    "total_case_series.columns = ['date', 'total_case']\n",
    "# Set the 'date' column as the index\n",
    "total_case_series.set_index('date', inplace=True)\n",
    "total_case_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIALECT = \"mysql\"\n",
    "SQL_DRIVER = \"pymysql\"\n",
    "USERNAME = \"user\"\n",
    "PASSWORD = \"user\"\n",
    "HOST = \"dengue-db\"\n",
    "PORT = 3306\n",
    "DBNAME = \"dengue\"\n",
    "\n",
    "conn_str = DIALECT + \"+\" + SQL_DRIVER + \"://\" + USERNAME + \":\" +quote(PASSWORD) + \"@\" + HOST + \":\" +str(PORT) + \"/\" + DBNAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_case = uscon['total_case']\n",
    "old_case = old_case.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sa.create_engine(conn_str).connect() as con:\n",
    "  old_case.to_sql(\"allcase\",con,index=None, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_case = total_case_series['total_case'].astype(int)\n",
    "forecast_case = forecast_case.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sa.create_engine(conn_str).connect() as con:\n",
    "  forecast_case.to_sql(\"allcase\",con,index=None, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('uploaded all case success...')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
