{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlalchemy as sa\n",
    "from urllib.parse import quote\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "import datetime\n",
    "\n",
    "from pylab import rcParams\n",
    "\n",
    "import warnings; \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              date   time   press source_file\n",
      "0       2022-01-01  00:00    -999  STH007.csv\n",
      "1       2022-01-01  01:00    -999  STH007.csv\n",
      "2       2022-01-01  02:00    -999  STH007.csv\n",
      "3       2022-01-01  03:00    -999  STH007.csv\n",
      "4       2022-01-01  04:00    -999  STH007.csv\n",
      "...            ...    ...     ...         ...\n",
      "500131  2020-07-31  19:00  1003.7    BUKT.csv\n",
      "500132  2020-07-31  20:00  1004.5    BUKT.csv\n",
      "500133  2020-07-31  21:00  1005.3    BUKT.csv\n",
      "500134  2020-07-31  22:00  -999.0    BUKT.csv\n",
      "500135  2020-07-31  23:00  -999.0    BUKT.csv\n",
      "\n",
      "[500136 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Specify the directory containing the CSV files\n",
    "directory = r'data/'  # Use raw string to handle backslashes\n",
    "# amp = [\n",
    "#     'BUKT.csv',\n",
    "#     'CIHO.csv',\n",
    "#     'SAY001.csv',\n",
    "#     'SAY002.csv',\n",
    "#     'STH005.csv',\n",
    "#     'STH007.csv',\n",
    "#     'STH010.csv',\n",
    "#     'STH011.csv',\n",
    "#     'STH013.csv',\n",
    "#     'STH014.csv',\n",
    "#     'STH019.csv',\n",
    "#     'STH021.csv',\n",
    "#     'STH022.csv',\n",
    "#     'STH023.csv',\n",
    "#     'STH025.csv',\n",
    "#     'STH026.csv'\n",
    "# ]\n",
    "amp = [\n",
    "    'BUKT.csv',\n",
    "    'STH005.csv',\n",
    "    'STH007.csv',\n",
    "    'STH010.csv',\n",
    "    'STH011.csv',\n",
    "    'STH014.csv',\n",
    "    'STH019.csv',\n",
    "    'STH021.csv',\n",
    "    'STH022.csv',\n",
    "    'STH023.csv',\n",
    "    'STH025.csv',\n",
    "    'STH026.csv'\n",
    "]\n",
    "# Read each CSV file into a DataFrame, add a new column, and store them in a list\n",
    "dataframes = []\n",
    "for dirpath, _, filenames in os.walk(directory):\n",
    "    for file in filenames:\n",
    "        if file.endswith('.csv'):\n",
    "            if file in amp:\n",
    "                # print(file)\n",
    "                file_path = os.path.join(dirpath, file)\n",
    "                try:\n",
    "                    df = pd.read_csv(file_path)\n",
    "                    # df['source_file'] = os.path.relpath(file_path, directory)  # Add a new column with the relative file path\n",
    "                    df['source_file'] = file\n",
    "                    dataframes.append(df)\n",
    "                except FileNotFoundError:\n",
    "                    print(f\"File not found: {file_path}\")\n",
    "                except pd.errors.EmptyDataError:\n",
    "                    print(f\"File is empty: {file_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading {file_path}: {e}\")\n",
    "\n",
    "# Optionally, concatenate all DataFrames into a single DataFrame\n",
    "if dataframes:\n",
    "    all_data = pd.concat(dataframes, ignore_index=True)\n",
    "    # Now 'all_data' contains all the data from the CSV files with an additional column 'source_file'\n",
    "    # print(all_data)\n",
    "else:\n",
    "    print(\"No dataframes to concatenate.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "press = pd.DataFrame(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500136 entries, 0 to 500135\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   date         500136 non-null  object\n",
      " 1   time         500136 non-null  object\n",
      " 2   press        500136 non-null  object\n",
      " 3   source_file  500136 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 15.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# press.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>press</th>\n",
       "      <th>source_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500131</th>\n",
       "      <td>2020-07-31</td>\n",
       "      <td>19:00</td>\n",
       "      <td>1003.7</td>\n",
       "      <td>BUKT.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500132</th>\n",
       "      <td>2020-07-31</td>\n",
       "      <td>20:00</td>\n",
       "      <td>1004.5</td>\n",
       "      <td>BUKT.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500133</th>\n",
       "      <td>2020-07-31</td>\n",
       "      <td>21:00</td>\n",
       "      <td>1005.3</td>\n",
       "      <td>BUKT.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500134</th>\n",
       "      <td>2020-07-31</td>\n",
       "      <td>22:00</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>BUKT.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500135</th>\n",
       "      <td>2020-07-31</td>\n",
       "      <td>23:00</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>BUKT.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date   time   press source_file\n",
       "500131  2020-07-31  19:00  1003.7    BUKT.csv\n",
       "500132  2020-07-31  20:00  1004.5    BUKT.csv\n",
       "500133  2020-07-31  21:00  1005.3    BUKT.csv\n",
       "500134  2020-07-31  22:00  -999.0    BUKT.csv\n",
       "500135  2020-07-31  23:00  -999.0    BUKT.csv"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# press.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip any leading/trailing whitespace from the date strings\n",
    "press['date'] = press['date'].str.strip()\n",
    "# temp['date'] = datetime.strptime(temp['date'], '%Y-%m-%d')\n",
    "# Convert 'DATESICK' column to datetime\n",
    "press['date'] = pd.to_datetime(press['date'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace -999.0 with NaN\n",
    "press['press'] = press['press'].replace(-999.0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'temp' column to numeric, coercing errors to NaN\n",
    "press['press'] = pd.to_numeric(press['press'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "press.drop(['time'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500136 entries, 0 to 500135\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   date         500136 non-null  datetime64[ns]\n",
      " 1   press        363906 non-null  float64       \n",
      " 2   source_file  500136 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(1), object(1)\n",
      "memory usage: 11.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# press.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>press</th>\n",
       "      <th>source_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>STH007.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>STH007.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>STH007.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>STH007.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>STH007.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  press source_file\n",
       "0 2022-01-01    NaN  STH007.csv\n",
       "1 2022-01-01    NaN  STH007.csv\n",
       "2 2022-01-01    NaN  STH007.csv\n",
       "3 2022-01-01    NaN  STH007.csv\n",
       "4 2022-01-01    NaN  STH007.csv"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# press.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series has date                0\n",
      "press          136230\n",
      "source_file         0\n",
      "dtype: int64 missing values\n"
     ]
    }
   ],
   "source": [
    "# print('Series has {} missing values'.format(press.isna().sum()))\n",
    "date_missed = press[press.isna()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by the relevant column(s), ensure that 'date' is part of the index\n",
    "press.set_index(['source_file', 'date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting just the date index to work with it directly\n",
    "df_resampled = press.groupby(level='source_file').apply(\n",
    "    lambda x: x.droplevel('source_file').resample('W-mon').mean().interpolate(method='linear')\n",
    ")\n",
    "\n",
    "# Reassigning the group level back to the resampled data\n",
    "# df_resampled['source_file'] = df_resampled.index.get_level_values(0)\n",
    "# df_resampled.set_index(['source_file', df_resampled.index], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Reset the index if needed\n",
    "df_resampled = df_resampled.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series has source_file     0\n",
      "date            0\n",
      "press          62\n",
      "dtype: int64 missing values\n"
     ]
    }
   ],
   "source": [
    "# print('Series has {} missing values'.format(df_resampled.isna().sum()))\n",
    "date_missed = df_resampled[df_resampled.isna()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the MultiIndex to work with 'date' as a regular column\n",
    "df_reset = press.reset_index()\n",
    "\n",
    "# Set 'date' as the index for resampling\n",
    "df_reset.set_index('date', inplace=True)\n",
    "\n",
    "# Resample the DataFrame based on the 'date' index\n",
    "df_resampled = df_reset.groupby('source_file').resample('W-mon').mean().interpolate(method='linear')\n",
    "\n",
    "# Reset index to reintroduce 'group' as a column\n",
    "df_resampled = df_resampled.reset_index(level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series has source_file    0\n",
      "press          0\n",
      "dtype: int64 missing values\n"
     ]
    }
   ],
   "source": [
    "# print('Series has {} missing values'.format(df_resampled.isna().sum()))\n",
    "date_missed = df_resampled[df_resampled.isna()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = df_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 3132 entries, 2019-01-07 to 2024-01-01\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   source_file  3132 non-null   object \n",
      " 1   press        3132 non-null   float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 73.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# newdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = newdf.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ST9601 =  newdf.groupby('date')[\"press\"].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 261 entries, 0 to 260\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   date    261 non-null    datetime64[ns]\n",
      " 1   press   261 non-null    float64       \n",
      "dtypes: datetime64[ns](1), float64(1)\n",
      "memory usage: 4.2 KB\n"
     ]
    }
   ],
   "source": [
    "ST9601.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ST9601['source_file'] = 'ST9601'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>press</th>\n",
       "      <th>source_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>1008.002678</td>\n",
       "      <td>ST9601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-14</td>\n",
       "      <td>1007.790922</td>\n",
       "      <td>ST9601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-21</td>\n",
       "      <td>1007.519514</td>\n",
       "      <td>ST9601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-28</td>\n",
       "      <td>1008.248065</td>\n",
       "      <td>ST9601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-02-04</td>\n",
       "      <td>1008.213114</td>\n",
       "      <td>ST9601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date        press source_file\n",
       "0 2019-01-07  1008.002678      ST9601\n",
       "1 2019-01-14  1007.790922      ST9601\n",
       "2 2019-01-21  1007.519514      ST9601\n",
       "3 2019-01-28  1008.248065      ST9601\n",
       "4 2019-02-04  1008.213114      ST9601"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ST9601.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf3 = pd.concat([newdf, ST9601], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3393 entries, 0 to 3392\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   date         3393 non-null   datetime64[ns]\n",
      " 1   source_file  3393 non-null   object        \n",
      " 2   press        3393 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(1), object(1)\n",
      "memory usage: 79.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# newdf3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf3['source_file'] = newdf3['source_file'].replace('ST9601', '9601')\n",
    "newdf3['source_file'] = newdf3['source_file'].replace('STH007.csv', '9602')\n",
    "newdf3['source_file'] = newdf3['source_file'].replace('STH023.csv', '9603')\n",
    "newdf3['source_file'] = newdf3['source_file'].replace('STH011.csv', '9604')\n",
    "newdf3['source_file'] = newdf3['source_file'].replace('STH005.csv', '9605')\n",
    "newdf3['source_file'] = newdf3['source_file'].replace('STH022.csv', '9606')\n",
    "newdf3['source_file'] = newdf3['source_file'].replace('STH019.csv', '9607')\n",
    "newdf3['source_file'] = newdf3['source_file'].replace('STH021.csv', '9608')\n",
    "newdf3['source_file'] = newdf3['source_file'].replace('STH014.csv', '9609')\n",
    "newdf3['source_file'] = newdf3['source_file'].replace('STH010.csv', '9610')\n",
    "newdf3['source_file'] = newdf3['source_file'].replace('BUKT.csv', '9611')\n",
    "newdf3['source_file'] = newdf3['source_file'].replace('STH026.csv', '9612')\n",
    "newdf3['source_file'] = newdf3['source_file'].replace('STH025.csv', '9613')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf3.rename(columns={'source_file': \"station\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3393 entries, 0 to 3392\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype         \n",
      "---  ------   --------------  -----         \n",
      " 0   date     3393 non-null   datetime64[ns]\n",
      " 1   station  3393 non-null   object        \n",
      " 2   press    3393 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(1), object(1)\n",
      "memory usage: 79.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# newdf3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIALECT = \"mysql\"\n",
    "SQL_DRIVER = \"pymysql\"\n",
    "USERNAME = \"user\"\n",
    "PASSWORD = \"user\"\n",
    "HOST = \"dengue-db\"\n",
    "PORT = 3306\n",
    "DBNAME = \"dengue\"\n",
    "\n",
    "conn_str = DIALECT + \"+\" + SQL_DRIVER + \"://\" + USERNAME + \":\" +quote(PASSWORD) + \"@\" + HOST + \":\" +str(PORT) + \"/\" + DBNAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sa.create_engine(conn_str).connect() as con:\n",
    "  newdf3.to_sql(\"pressure\",con,index=None, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('uploaded pressure success...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf3.to_csv(r\"data/dataset/press_all.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
